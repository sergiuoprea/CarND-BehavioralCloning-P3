{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning P3\n",
    "### Self driving cars nanodegree at Udacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "#Loading our data\n",
    "import csv as csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D, MaxPooling2D, Activation, Cropping2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "In order to load our data we firstly read the driving_log.csv file which contains the paths to the left, center and right cameras and also info about steering angle, throttle, break and speed. \n",
    "\n",
    "We will want to automate the loading process in order to easily load our own data which is stored in different directories. For that we used several libraries such as csv (read csv files) and cv2 (read images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils\n",
    "\n",
    "#Reading the csv file\n",
    "def readCSV(in_csv_path, in_path):\n",
    "    lines = []\n",
    "    with open(in_csv_path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader, None) #Skip header\n",
    "        for line in reader:\n",
    "            #Correct images paths\n",
    "            line_aux = []\n",
    "            #Center image\n",
    "            line_aux.append(in_path + line[0].split('/')[-1])\n",
    "            #Left image\n",
    "            line_aux.append(in_path + line[1].split('/')[-1])\n",
    "            #Right image\n",
    "            line_aux.append(in_path + line[2].split('/')[-1])\n",
    "            #Steering angle\n",
    "            line_aux.append(float(line[3]))\n",
    "            \n",
    "            lines.append(line_aux)\n",
    "            \n",
    "    return lines\n",
    "\n",
    "#Read center image and steering angle\n",
    "def readData_Basic(in_lines):\n",
    "    images = []\n",
    "    measurements = []\n",
    "    \n",
    "    for line in in_lines:\n",
    "        image = cv2.imread(line[0])\n",
    "        images.append(image)\n",
    "        measurements.append(line[3])\n",
    "    \n",
    "    return np.array(images), np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = './data/IMG/'\n",
    "csv_path = './data/driving_log.csv'\n",
    "\n",
    "csv_lines = readCSV(csv_path, imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center image path- ./data/IMG/center_2016_12_01_13_30_48_404.jpg. Left image path- ./data/IMG/left_2016_12_01_13_30_48_404.jpg. Right image path- ./data/IMG/right_2016_12_01_13_30_48_404.jpg. Steering Angle- 0.0.\n"
     ]
    }
   ],
   "source": [
    "#Explore the data\n",
    "csv_line_number = 1\n",
    "\n",
    "current_line = csv_lines[csv_line_number]\n",
    "print(\"Center image path- {}. Left image path- {}. Right image path- {}. Steering Angle- {}.\".format(current_line[0], current_line[1], current_line[2], current_line[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "To grayscale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_yuv(in_image):\n",
    "    return cv2.cvtColor(in_image, cv2.COLOR_BGR2YUV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic neural network using Keras\n",
    "\n",
    "We will implement a basic neural network in order to verify that everything is working before implementing a more complex model. This network will just going to be a flattened image connected to a single output node. This single output node will predict the stearing angle, thus converting this model into a regression network. In contrast with a classification network, we may apply a softmax activation function to the output layer. Nevertheless in this case we will not use an activation function. We will directly predict the steering measurement. \n",
    "\n",
    "For this basic implementation we will use Keras as a library which works with tensorflow as backend. This will simplify our implementation and will be great for prototyping. Let's go ahead!\n",
    "\n",
    "Improvement 1: In order to improve our model we need to preprocess our input data. For that we will add two preprocessing steps: normalization and  mean centering the data. We will add a lambda layer to our model. After doing this, we can decrease the training epochs a lot. We will fix the number of epochs in 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model():\n",
    "    #Model definition\n",
    "    model = Sequential()\n",
    "    #Lambda layer for normalizing our data. In order to mean center the data, we will\n",
    "    #need to substract -0.5 (shifting the model down) to the normalized data. \n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "    model.add(Flatten(input_shape=(160,320,3)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a more complex network such as LeNet-5 architecture\n",
    "\n",
    "We will implement LeNet-5 architecture using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet_5():\n",
    "    model = Sequential()\n",
    "    #Lambda layer for normalizing our data. In order to mean center the data, we will\n",
    "    #need to substract -0.5 (shifting the model down) to the normalized data. \n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "    #First set of CONV => RELU => POOL\n",
    "    model.add(Conv2D(3, (5, 5), input_shape=(160,320,3), activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size= (2, 2), strides= (2, 2)))\n",
    "\n",
    "    #Second set of CONV => RELU => POOL\n",
    "    model.add(Conv2D(6, (5, 5), activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size= (2, 2), strides= (2, 2)))\n",
    "\n",
    "    #Setting the FCs layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120))\n",
    "    model.add(Dense(84))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Training set shape:  (8036, 160, 320, 3)\n",
      "Training set labels shape:  (8036,)\n",
      "BASIC MODEL training\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/2\n",
      "6428/6428 [==============================] - 3s 530us/step - loss: 2.0965 - val_loss: 1.3814\n",
      "Epoch 2/2\n",
      "6428/6428 [==============================] - 2s 376us/step - loss: 2.9891 - val_loss: 3.1842\n",
      "******************************************\n",
      "\n",
      "LENET-5 MODEL training\n",
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/2\n",
      "6428/6428 [==============================] - 6s 865us/step - loss: 1.0779 - val_loss: 0.0139\n",
      "Epoch 2/2\n",
      "6428/6428 [==============================] - 4s 634us/step - loss: 0.0113 - val_loss: 0.0118\n",
      "******************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading data with center image and measurements\n",
    "X_train_basic, y_train_basic = readData_Basic(csv_lines)\n",
    "print('Data loaded successfully!')\n",
    "\n",
    "print(\"Training set shape: \", X_train_basic.shape)\n",
    "print(\"Training set labels shape: \", y_train_basic.shape)\n",
    "\n",
    "\n",
    "#RUNNING BASIC MODEL\n",
    "print(\"BASIC MODEL training\")\n",
    "\n",
    "basic_model = basic_model()\n",
    "#Model compilation\n",
    "#For the loss function we will use Mean Squared Error (MSE). We will minimize the \n",
    "#error between the steering measurement which the network predicts and the ground \n",
    "#truth steering measurements provided by the dataset\n",
    "basic_model.compile(loss='mse', optimizer='adam')\n",
    "#we also shuffle the data and split off 20% of the data to use for a validation set\n",
    "basic_model.fit(X_train_basic, y_train_basic, validation_split=0.2, shuffle=True, epochs= 2)\n",
    "\n",
    "#Keras by default will run 10 epochs. Nevertheless with 10 epochs we will \n",
    "#overfit the training data. For that reason we will only perform 6 epochs\n",
    "basic_model.save('basic_model.h5')\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "print(\"******************************************\")\n",
    "print()\n",
    "\n",
    "#RUNNING LENET-5 MODEL\n",
    "print(\"LENET-5 MODEL training\")\n",
    "\n",
    "lenet5_model = lenet_5()\n",
    "\n",
    "#Model compilation\n",
    "lenet5_model.compile(loss='mse', optimizer='adam')\n",
    "lenet5_model.fit(X_train_basic, y_train_basic, validation_split=0.2, shuffle=True, epochs= 2)\n",
    "lenet5_model.save('lenet_model.h5')\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "print(\"******************************************\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "In order to increase the number of data we have driven the car in the opposite direction along the routes. At the same time we can flip the images and also taking the opposite sign of steering measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipImg_invertMeas(in_image, in_measurement):\n",
    "    image_flipped = np.fliplr(in_image)\n",
    "    measurement_inverted = -in_measurement\n",
    "    \n",
    "    return image_flipped, measurement_inverted\n",
    "\n",
    "def augmentDataset(in_images, in_measurements, how_much= 0.3):\n",
    "    augmented_num = int(len(in_images) * how_much)\n",
    "    \n",
    "    #print(\"We will generate {} images and measurements.\".format(augmented_num))\n",
    "    \n",
    "    sklearn.utils.shuffle(in_images, in_measurements)\n",
    "\n",
    "    in_images = in_images[:augmented_num]\n",
    "    in_measurements = in_measurements[:augmented_num]\n",
    "    \n",
    "    if (len(in_images) == len(in_measurements)):\n",
    "        for index in range(0, len(in_images)):\n",
    "            current_img = in_images[index]\n",
    "            current_meas = in_measurements[index]\n",
    "            in_images[index], in_measurements[index] = flipImg_invertMeas(current_img, current_meas)\n",
    "    else:\n",
    "        print(\"Shouldn't be here!\")\n",
    "        return 0\n",
    "    \n",
    "    return in_images, in_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multiple Cameras\n",
    "\n",
    "Up to this point we only used the center camera. But, using side cameras should be a great decision because we will have three times more data. And also, using these images we will teach the network how to steer back to the center if the vehicle starts drifting off to the side. \n",
    "\n",
    "The simulator captures images from three cameras mounted on the car: a center, right and left camera. That’s because of the issue of recovering from being off-center. In the simulator, you can weave all over the road and turn recording on and off to record recovery driving. In a real car, however, that’s not really possible. At least not legally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData_Advanced(in_line, correction=0.25):\n",
    "    images = []\n",
    "    measurements = []\n",
    "    \n",
    "    center_img = cv2.imread(in_line[0])\n",
    "    left_img = cv2.imread(in_line[1])\n",
    "    right_img = cv2.imread(in_line[2])\n",
    "\n",
    "    #center_img = preprocess_image(center_img)\n",
    "    #left_img = preprocess_image(left_img)\n",
    "    #right_img = preprocess_image(right_img)\n",
    "\n",
    "    images.append(center_img)\n",
    "    images.append(left_img)\n",
    "    images.append(right_img)\n",
    "\n",
    "    #Measurements\n",
    "    center_steer = in_line[3]\n",
    "    left_steer = center_steer + correction\n",
    "    right_steer = center_steer - correction\n",
    "\n",
    "    measurements.append(center_steer)\n",
    "    measurements.append(left_steer)\n",
    "    measurements.append(right_steer)\n",
    "    \n",
    "    return images, measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nVidia Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NvidiaArchitecture():\n",
    "    model = Sequential()\n",
    "    #Preprocessing\n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "    model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "    \n",
    "    model.add(Conv2D(24,(5,5), strides=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(36,(5,5), strides=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(48,(5,5), strides=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "    model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32, data_augmentation=False):\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        \n",
    "        images_batch = []\n",
    "        measurements_batch = []\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "      \n",
    "            for batch_sample in batch_samples:\n",
    "                images_sample, measurements_sample = readData_Advanced(batch_sample)\n",
    "                images_batch.extend(images_sample)\n",
    "                measurements_batch.extend(measurements_sample)\n",
    "            \n",
    "            if data_augmentation:\n",
    "                images_augm, measurements_augm = augmentDataset(images_batch, measurements_batch, how_much= 0.3)\n",
    "                images_batch.extend(images_augm)\n",
    "                measurements_batch.extend(measurements_augm)\n",
    "        \n",
    "        \n",
    "        yield sklearn.utils.shuffle(np.asarray(images_batch), np.asarray(measurements_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train with 6428 samples.\n",
      "We will validate with 1608 samples.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_3 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 43, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 20, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 6, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               844900    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 981,819\n",
      "Trainable params: 981,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  from ipykernel import kernelapp as app\n",
      "/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=1024, epochs=28, steps_per_epoch=24000, validation_data=<generator...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n"
     ]
    }
   ],
   "source": [
    "train_samples, validation_samples = train_test_split(csv_lines, test_size= 0.2)\n",
    "\n",
    "print(\"We will train with {} samples.\".format(len(train_samples)))\n",
    "print(\"We will validate with {} samples.\".format(len(validation_samples)))\n",
    "\n",
    "train_generator = generator(train_samples, batch_size= 32, data_augmentation= False)\n",
    "validation_generator = generator(validation_samples, batch_size= 32, data_augmentation= False)\n",
    "\n",
    "model = NvidiaArchitecture()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary() \n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='auto')\n",
    "model.fit_generator(train_generator, samples_per_epoch=24000, nb_epoch=28, validation_data=validation_generator, nb_val_samples=1024)#, callbacks=[early_stop])\n",
    "\n",
    "model.save('nvidia_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
